Diary Entries:

Term 1:

27/10/2022: - Begun to research into the different types of Machine Learning Algorithms
            - looked in K-Nearest Neighbour, how it works and how to implement it

28/10/2022: - Installed scikit-learn 
            - Added dataset to repository

01/11/2022: - Started coding to Jupyter Notebook - so that all data can be visualised/compiled in one place
            - Researched the seaborn library to potentially visualise data on informative statistical graphic
            - Also Researched Pandas library - to potentially analyse datasets
            - split the data set using scikit-Learn
            - Created a method to work out the Euclidean distance between two points
            - Created a method to work out the KNN

03/11/2022: - Trying to convert .csv file into a .txt file - because reading the data set file by row has become difficult
            - Created a sort method to sort out the distances in ascending order
            - Used numpy's genfromtxt instead, but dataset is too large and takes too long to process

04/11/2022: - Cleaned the data: getting rid of model, transmission and fuel type.
            - Broke down dataset into first 200 entries, because dataset is too large to process
            - Created method for 1NN to test
            - Numpy's genfromtxt doesn't like the engineSize and tax variables - so I have left them out for the time being      

05/11/2022: - Created a prediction method to predict the price of the cars
            - Results from prediction method are returning in an unwanted format
            - Using Pandas library to read from library - for efficiency and better readings from the dataset
            - Created a seaborn heatmap to visualise dataset
            - Looked into Seaborn's distplots graph

17/11/2022: - Began writing the evaluation method for KNN - is currently suited for classification, not regression
            - Began work writing interim report.

18/11/2022: - Began writing the methodology in the interim report

21/11/2022: - Begun writing description of KNN algorithm to Interim report

23/11/2022: - Begun coding the decision tree algorithm: imported & split data, method using scikit-learn, entropy method
            - Begun writing description of decision algorithm to Interim report
            - Attempted to visualise the decision tree

25/11/2022: - Normalised data for KNN
            - Added preprocessing and normalization to Interim report
            - Removed unnecessary .txt files

26/11/2022: - Fixed issued with reading normalised data
            - Added code examples to interim report

29/11/2022: - Completed the evaluation method for KNN, using RMSE

30/11/2022: - Changed how I reduced data set to increase accuracy by 0.3 at peak
            - Used Pandas feature "get_dummies()" to generate dummy variables for model, transmission and fuel type
            - Created a user input to get prediction of their own car

01/12/2022: - Removed "get_dummies()" and replaced with "LabelEncoder()"
            - Completed user prediction input - fully working

02/12/2022: - Fixed an issue with prediction, where predictions were completely wrong - fixed by normalising user input


05/12/2022: - Worked on decision tree algorithm - understanding what each method does
            - Calculated how many times Euclidean distance is calculated and how long a single prediction takes
            - Described my KNN algorithm code in the interim report

06/12/2022: - Created Decision tree class
                - Initialised values
                - Created fit method to put features and label together
                - Created start of build tree method
                - Created method to find the best split

07/12/2022: - Created a method to find split tree into branches - extension of best split method
            - Using template entropy method to calculate entropy of a node - temporary to test later methods
            - Created method to calculate information gain
            - Completed best split and tree build methods
            - Created method to predict the price of a car - currently not working fully

08/12/2022: - Fixed predict and best split methods
            - Created method to evaluate and calculate the RMSE of the decision tree
            - Completed Interim report

Term 2:

16/12/2022: - KNN and decision tree algorithm work with all car models on dataset
            - Begun Final report
            - Created a Trello board to keep track of tasks
            
17/12/2022: - Installed PyQt5 to build GUI

19/12/2022: - Created a PyQt file and tested UI design
            - Created NN.py file for the K-Nearest Neighbour algorithm
                - Modified code of nearestNeighbour.ipynb that allows other files to access functions from the file
            - created "runUI.py" to run the GUI

20/12/2022: - Created an appealing UI design and a main page 
                - Main page with with radio buttons to choose which ML algorithm to use
                - Created a page for the KNN algorithm
                - Created a page to clearly state the predicted price

21/12/2022: - Created DT.py file for the decision tree algorithm
                - Modified code of decision_tree.ipynb that allows other files to access functions from the file
            - Created a separate UI page for the decision tree algorithm
            - Then made the decision tree and KNN algorithms use the same UI page - to reduce code

29/12/2022: - Converted GUI into a single executable file, so that it can be run on any Windows system
                - Faced problem with executable file not detecting the .ui files - fixed by putting UI files in a folder

23/01/2023: - Begun research into Random Forest 

25/01/2023: - Continuted research into Random Forest - taking notes
            - Created Jupyter Notebook page for Random Forest Algorithm
            - Perfromed GridSearchCV for Decision Tree to find the optimal parameters
            - Applied GridSearchCV parameters to my decision tree

29/01/2023: - Created Random Forest class with __init__ method

30/01/2023: - Imported, cleaned and split the dataset for the Random Forest code
            - Working on my Random Forest algorithm
                - testing bagging technique 

01/02/2023: - Created a fit method for the Random Forest algorithm  

03/02/2023: - Created a predict method for the Random Forest algorithm
            - Completed first draft of the Random Forest algorithm - it prints a different price each time

04/02/2023: - GridSearchCV performed on Random Forest algorithm
            - Further testing to solve problem with Random Forest algorithm, where the max depth can't be increased above 5
            - Re-implemented the entropy method into the Decision tree algorithm to test whether it improves accuracy

05/02/2023: - Removed entropy method from Decision Tree algorithm
            - Found optimal parameters for Random Forest algorithm - still faced problems where the max depth can't be increased above 5

16/02/2023: - Changed range of suitable parameters to limit the max depth to 6 - due to unknown error
            - change range of Decision trees parameters to the same range of the random forest parameters - to keep controlled varriables similar

17/02/2023: - Solved problem with random forest algorithm - the max depth can now be increased above 5
            - Created a method to evaluate the accuracy of the Random Forest algorithm
            - Fixed a problem with outputting the predicted price of the Random Forest algorithm - where only the output from one tree was Used
            - Removed random state from the sample method - as it was causing the same sample to be used each time

22/02/2023: - Worked on optimising the random forest algorithm
            - Created a method to calculate the RMSE of the Random Forest algorithm

05/03/2023: - Wrote up random forest on the final report

06/03/2023: - Solved issue and improved Random Forest code accuracy, by changing random state value to None.

07/03/2023: - Created more data visualisations
            - Begun working on and completed first draft of Linear Regrrssion algorithm

08/03/2023: - Begun working in Suport Vector Machine algorithm

12/03/2023: - Gotten rid out outliers in dataset
            - Created more data visualisations - of outliers

13/03/2023: - Added function to remove outliers in all algorithms
            - Begun write up on outliers